{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the ROOT-LBN Tutorial\n",
    "\n",
    "* Created: 11/03/2022\n",
    "* Contact: dennis . noll [at] cern . ch\n",
    "\n",
    "This notbook showcases, how a simple classification between two physics processes can be implemented using the Lorentz Boost Network ([LBN](https://arxiv.org/abs/1812.09722)).\n",
    "We will start with two **root files** and end with a fully trained classifier which can be applied on **numpy arrays**.\n",
    "\n",
    "For input data we use NANOAOD simulations following `RunIIFall17NanoAODv6`.\n",
    "The two root files contain physics events from two different processes with the same final state:\n",
    "* `signal.root`: GluGluToHHTo2B2WToLNu2J_node_SM\n",
    "* `background.root`: TTToSemiLeptonic\n",
    "\n",
    "All the needed software is pinned in the `environment.yml` file.\n",
    "It can be installed and sourced using [`conda`](https://docs.conda.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import vector\n",
    "from lbn import LBN, LBNLayer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for correct tensorflow version and GPU availability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU: []\n"
     ]
    }
   ],
   "source": [
    "assert tf.__version__.startswith(\"2\")\n",
    "print(\"Available GPU:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Define some functions to turn root tuples into numpy arrays consisting of the momentum four vectors of particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_array(tree, part=\"Jet\", n=4):\n",
    "    particles = vector.awk({\n",
    "        \"pt\": tree[f\"{part}_pt\"].array(),\n",
    "        \"phi\": tree[f\"{part}_phi\"].array(),\n",
    "        \"eta\": tree[f\"{part}_eta\"].array(),\n",
    "        \"M\": tree[f\"{part}_mass\"].array(),\n",
    "    })\n",
    "    array = np.array(\n",
    "        np.stack(\n",
    "            [\n",
    "                ak.fill_none(ak.pad_none(particles.E, n, clip=True), 0)[:, :n],\n",
    "                ak.fill_none(ak.pad_none(particles.x, n, clip=True), 0)[:, :n],\n",
    "                ak.fill_none(ak.pad_none(particles.y, n, clip=True), 0)[:, :n],\n",
    "                ak.fill_none(ak.pad_none(particles.z, n, clip=True), 0)[:, :n],\n",
    "            ],\n",
    "            axis=-1\n",
    "        )\n",
    "    )\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data for signal and background:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"/eos/user/d/dnoll/HH/lbn/%s.root\"\n",
    "signal, background = uproot.open(DATA_PATH % \"signal\"), uproot.open(DATA_PATH % \"background\")\n",
    "signal_tree, background_tree = signal[\"Events\"], background[\"Events\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple example we will select events with exactly one electron with transverse momentum greater than 25 GeV and equal or more than four jets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_selection(tree):\n",
    "    e_mask = tree[\"nElectron\"].array() == 1\n",
    "    pt_mask = ak.any(tree[\"Electron_pt\"].array() > 25, axis=-1)\n",
    "    jet_mask = tree[\"nJet\"].array() >=4\n",
    "    return e_mask * pt_mask * jet_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a boolean mask for the event selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_mask, background_mask = event_selection(signal_tree), event_selection(background_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specification of low and high level input data. As low level inputs, we will use the four momenta of the four jets with the highest momentum, and the electron, as high level feature we will use the variable \"MET_pt\" which is defined on the event level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_low_level(tree):\n",
    "    jets = tree_to_array(tree, part=\"Jet\", n=4)\n",
    "    electron = tree_to_array(tree, part=\"Electron\", n=1)\n",
    "    events = np.concatenate([jets, electron], axis=1)\n",
    "    return events\n",
    "\n",
    "def get_high_level(tree, variables=[\"MET_pt\"]):\n",
    "    output = np.array([tree[variable].array() for variable in variables])\n",
    "    return np.moveaxis(output, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get low and high level data, which will be used for the LBN and the following DNN respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_ll, signal_hl = get_low_level(signal_tree), get_high_level(signal_tree)\n",
    "background_ll, background_hl = get_low_level(background_tree), get_high_level(background_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask arrays according to selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_ll, signal_hl = signal_ll[signal_mask], signal_hl[signal_mask]\n",
    "background_ll, background_hl = background_ll[background_mask], background_hl[background_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode targets to one_hot vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 11:44:45.587557: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "signal_targets = tf.keras.backend.one_hot(np.ones(signal_ll.shape[0]), 2)\n",
    "background_targets = tf.keras.backend.one_hot(np.zeros(background_ll.shape[0]), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a factor ~10 more background than signal events and have to explicitly care that the network does not only concentrate on the background class.\n",
    "One option is to use a class weight on each event in the loss function, giving a small weight to the background and a large weight to the signal.\n",
    "This approach works fine if the size differences between the classes are not too large.\n",
    "We will use it in this example. Because the differences are already pretty large (factor ~10), our validation accuracy will fluctuate.\n",
    "If the differences are to large, we have to crop the larger class or, as an even better approach, sample up the smaller class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_signal = signal_ll.shape[0]\n",
    "# background_ll, background_hl, background_targets = background_ll[:n_signal], background_hl[:n_signal], background_targets[:n_signal]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate and shuffle signal and background samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_together(*arrays):\n",
    "    first_array = arrays[0]\n",
    "    assert [len(first_array) == len(array) for array in arrays[1:]]\n",
    "    p = np.random.permutation(len(first_array))\n",
    "    return [array[p] for array in arrays]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = np.concatenate([signal_ll, background_ll], axis=0).astype(np.float32)\n",
    "hl = np.concatenate([signal_hl, background_hl], axis=0).astype(np.float32)\n",
    "targets = np.concatenate([signal_targets, background_targets], axis=0)\n",
    "\n",
    "ll, hl, targets = shuffle_together(ll, hl, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize high-level features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_mean, hl_std = np.mean(hl, axis=0), np.std(hl, axis=0)\n",
    "hl = (hl - hl_mean) / hl_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape LL (146209, 5, 4)\n",
      "Shape HL (146209, 1)\n",
      "Shape targets (146209, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape LL\", ll.shape)\n",
    "print(\"Shape HL\", hl.shape)\n",
    "print(\"Shape targets\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data, use 90% for training and 10% for validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into 131588 training and 14621 validation events\n"
     ]
    }
   ],
   "source": [
    "n_data = ll.shape[0]\n",
    "split = int(n_data * 0.9)\n",
    "print(\"Splitting data into\", split, \"training and\", n_data-split, \"validation events\")\n",
    "\n",
    "ll_train, hl_train, ll_val, hl_val = ll[:split], hl[:split], ll[split:], hl[split:]\n",
    "y_train, y_val = targets[:split], targets[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the class weights which we will later use in the fit procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weight: {0: 0.5550371647015055, 1: 5.042385156573321}\n"
     ]
    }
   ],
   "source": [
    "i_targets = np.argmax(targets, axis=1)\n",
    "class_weight = compute_class_weight('balanced', classes=np.unique(i_targets), y=i_targets)\n",
    "class_weight = dict(enumerate(class_weight))\n",
    "print(\"Class weight:\", class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "Now we set up the model with `tf.keras`.\n",
    "First some general network parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "n_nodes = 256\n",
    "activation = \"relu\"\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the functional API, where we can feed two inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_inputs = tf.keras.Input(shape=(5, 4), name=\"LL\")\n",
    "hl_inputs = tf.keras.Input(shape=(1,), name=\"HL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Lorentz Boost Network and use it as first layer of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbn_layer = LBNLayer(ll_inputs.shape, 10, boost_mode=LBN.PAIRS, features=[\"E\", \"pt\", \"eta\", \"phi\", \"m\", \"pair_cos\"])\n",
    "lbn_features = lbn_layer(ll_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the features from the LBN (energy, transverse momentum, ...) with a BatchNormalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_lbn_features = tf.keras.layers.BatchNormalization()(lbn_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the normalized features from the LBN and the high level features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.concatenate([normalized_lbn_features, hl_inputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the feed forward network constisting of some dense layers with dropout between the layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Dense(n_nodes, activation=activation)(x)\n",
    "x = tf.keras.layers.Dropout(dropout)(x)\n",
    "x = tf.keras.layers.Dense(n_nodes, activation=activation)(x)\n",
    "x = tf.keras.layers.Dropout(dropout)(x)\n",
    "outputs = tf.keras.layers.Dense(n_classes)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[ll_inputs, hl_inputs], outputs=outputs, name='lbn_dnn')\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a summary of the created model with the number of total trainable variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lbn_dnn\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " LL (InputLayer)                [(None, 5, 4)]       0           []                               \n",
      "                                                                                                  \n",
      " LBN (LBNLayer)                 (None, 95)           100         ['LL[0][0]']                     \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 95)          380         ['LBN[0][0]']                    \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " HL (InputLayer)                [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 96)           0           ['batch_normalization[0][0]',    \n",
      "                                                                  'HL[0][0]']                     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          24832       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          65792       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 256)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 2)            514         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 91,618\n",
      "Trainable params: 91,428\n",
      "Non-trainable params: 190\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "At last, fit the model to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "129/129 [==============================] - 11s 61ms/step - loss: 0.6652 - accuracy: 0.6140 - val_loss: 0.7466 - val_accuracy: 0.5091\n",
      "Epoch 2/5\n",
      "129/129 [==============================] - 10s 74ms/step - loss: 0.6397 - accuracy: 0.6536 - val_loss: 0.6473 - val_accuracy: 0.6398\n",
      "Epoch 3/5\n",
      "129/129 [==============================] - 6s 48ms/step - loss: 0.6303 - accuracy: 0.6600 - val_loss: 0.6334 - val_accuracy: 0.6552\n",
      "Epoch 4/5\n",
      "129/129 [==============================] - 6s 43ms/step - loss: 0.6241 - accuracy: 0.6626 - val_loss: 0.6023 - val_accuracy: 0.6898\n",
      "Epoch 5/5\n",
      "129/129 [==============================] - 5s 40ms/step - loss: 0.6190 - accuracy: 0.6662 - val_loss: 0.6086 - val_accuracy: 0.6733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d3137370>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    [ll_train, hl_train],\n",
    "    y_train,\n",
    "    epochs=5,\n",
    "    batch_size=1024,\n",
    "    class_weight=class_weight,\n",
    "    validation_data=([ll_val, hl_val], y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot a simple confusion matrix for the final classificaiton:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    figure = plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=\"summer\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(i, j, cm[i, j], horizontalalignment=\"center\", size=18)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(\"hh_tt.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_val = model.predict([ll_val, hl_val], batch_size=1024)\n",
    "cm = confusion_matrix(np.argmax(y_val, axis=1), np.argmax(pred_val, axis=1))\n",
    "plot_confusion_matrix(cm, [\"TT\", \"HH\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "root_to_lbn2",
   "language": "python",
   "name": "root_to_lbn2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
